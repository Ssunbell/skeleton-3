{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBMRC-8eG2Fh"
   },
   "source": [
    "### **Objectives**\n",
    "\n",
    "1. ì‹¤ìŠµëª… : \n",
    "2. í•µì‹¬ ì£¼ì œ:\n",
    "    1. Pseudo Labeled ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸° ë° EDA\n",
    "    2. base ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    3. Text-to-SQL task ë°ì´í„° ì „ì²˜ë¦¬\n",
    "    4. Text-to-SQL task ëª¨ë¸ LoRA fine-tuning\n",
    "3. í•™ìŠµ ëª©í‘œ :\n",
    "    1. Pseudo Labeled ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ê³  EDAë¥¼ í•  ìˆ˜ ìˆë‹¤.\n",
    "    2. Text-to-SQL task í•™ìŠµì„ ìœ„í•œ base ëª¨ë¸ ë° í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.\n",
    "    3. Pseudo Labeled ë°ì´í„°ì…‹ì˜ ì „ì²˜ë¦¬ ì „ëµì„ ìˆ˜ë¦½í•  ìˆ˜ ìˆë‹¤.\n",
    "    4. base ëª¨ë¸ì— LoRA fine-tuningì„ ì§„í–‰í•  ìˆ˜ ìˆë‹¤.\n",
    "4. í•™ìŠµ ê°œë…: í‚¤ì›Œë“œëª… :\n",
    "    1. EDA\n",
    "    2. Text-to-SQL\n",
    "    3. LoRA fine-tuning\n",
    "5. í•™ìŠµ ë°©í–¥ :\n",
    "  - Text-to-SQLì´ë¼ëŠ” íŠ¹ì • taskì— ëŒ€í•´ì„œ íŠ¹í™”ì‹œí‚¤ëŠ” LoRA fine-tuningì„ ì§„í–‰í•©ë‹ˆë‹¤. ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì•„ì‰¬ìš¸ ê²½ìš° í•™ìŠµ ë°ì´í„°ì™€ ì ì€ GPU ë©”ëª¨ë¦¬ë¡œë„ ì„±ëŠ¥ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë†’ì¼ ìˆ˜ ìˆëŠ” ë°©ë²•ì— ëŒ€í•´ì„œ ì²´ë“í•©ë‹ˆë‹¤.\n",
    "  - ì‹¤ìŠµ ì½”ë“œëŠ” ì¡°êµê°€ ì§ì ‘ êµ¬í˜„í•œ ì½”ë“œë¥¼ ì°¸ê³ í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "  - í•´ë‹¹ ì‹¤ìŠµì€ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ê²½ìš° ë¬´ì—‡ì´ í•„ìš”í•˜ê³  ì–´ë–»ê²Œ í•˜ë©´ í•™ìŠµì„ íš¨ìœ¨ì ìœ¼ë¡œ í•  ìˆ˜ ìˆëŠ”ì§€ ê³ ë¯¼í•´ë´…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prerequisites**\n",
    "```\n",
    "numpy==2.1.0\n",
    "pandas==2.2.3\n",
    "transformers==4.56.0\n",
    "torch==2.8.0+cu126\n",
    "accelerate==1.10.1\n",
    "datasets==4.0.0\n",
    "peft==0.17.1\n",
    "trl==0.22.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëœë¤ì„±ì„ ì œì–´í•˜ê¸° ìœ„í•´ seedë¥¼ ê³ ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UXrsTMkd01i-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# tqdmì´ í…ìŠ¤íŠ¸ ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì • (ipywidgets ì—ëŸ¬ ë°©ì§€)\n",
    "os.environ[\"TQDM_DISABLE\"] = \"0\"\n",
    "os.environ[\"TQDM_MININTERVAL\"] = \"1\"\n",
    "\n",
    "# ì‹œë“œ ì„¤ì •\n",
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-_D1uG2G67l"
   },
   "source": [
    "# 1. ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸° ë° EDA\n",
    "\n",
    "- í•™ìŠµ ëª©í‘œ : ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œ EDAë¥¼ í•  ìˆ˜ ìˆë‹¤.\n",
    "- í•™ìŠµ ê°œë… : EDA\n",
    "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
    "    - ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    - ë°ì´í„°ì…‹ EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mk1Fi9wMTo-"
   },
   "source": [
    "ì²¨ë¶€í•œ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZD1ZxAduG8ra"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "      <th>query_toks</th>\n",
       "      <th>query_toks_no_value</th>\n",
       "      <th>question_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT count(*) FROM head WHERE age  &gt;  56</td>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "      <td>['SELECT' 'count' '(' '*' ')' 'FROM' 'head' 'W...</td>\n",
       "      <td>['select' 'count' '(' '*' ')' 'from' 'head' 'w...</td>\n",
       "      <td>['How' 'many' 'heads' 'of' 'the' 'departments'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT name ,  born_state ,  age FROM head ORD...</td>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "      <td>['SELECT' 'name' ',' 'born_state' ',' 'age' 'F...</td>\n",
       "      <td>['select' 'name' ',' 'born_state' ',' 'age' 'f...</td>\n",
       "      <td>['List' 'the' 'name' ',' 'born' 'state' 'and' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT creation ,  name ,  budget_in_billions ...</td>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "      <td>['SELECT' 'creation' ',' 'name' ',' 'budget_in...</td>\n",
       "      <td>['select' 'creation' ',' 'name' ',' 'budget_in...</td>\n",
       "      <td>['List' 'the' 'creation' 'year' ',' 'name' 'an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT max(budget_in_billions) ,  min(budget_i...</td>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "      <td>['SELECT' 'max' '(' 'budget_in_billions' ')' '...</td>\n",
       "      <td>['select' 'max' '(' 'budget_in_billions' ')' '...</td>\n",
       "      <td>['What' 'are' 'the' 'maximum' 'and' 'minimum' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>department_management</td>\n",
       "      <td>SELECT avg(num_employees) FROM department WHER...</td>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "      <td>['SELECT' 'avg' '(' 'num_employees' ')' 'FROM'...</td>\n",
       "      <td>['select' 'avg' '(' 'num_employees' ')' 'from'...</td>\n",
       "      <td>['What' 'is' 'the' 'average' 'number' 'of' 'em...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   db_id                                              query  \\\n",
       "0  department_management         SELECT count(*) FROM head WHERE age  >  56   \n",
       "1  department_management  SELECT name ,  born_state ,  age FROM head ORD...   \n",
       "2  department_management  SELECT creation ,  name ,  budget_in_billions ...   \n",
       "3  department_management  SELECT max(budget_in_billions) ,  min(budget_i...   \n",
       "4  department_management  SELECT avg(num_employees) FROM department WHER...   \n",
       "\n",
       "                                            question  \\\n",
       "0  How many heads of the departments are older th...   \n",
       "1  List the name, born state and age of the heads...   \n",
       "2  List the creation year, name and budget of eac...   \n",
       "3  What are the maximum and minimum budget of the...   \n",
       "4  What is the average number of employees of the...   \n",
       "\n",
       "                                          query_toks  \\\n",
       "0  ['SELECT' 'count' '(' '*' ')' 'FROM' 'head' 'W...   \n",
       "1  ['SELECT' 'name' ',' 'born_state' ',' 'age' 'F...   \n",
       "2  ['SELECT' 'creation' ',' 'name' ',' 'budget_in...   \n",
       "3  ['SELECT' 'max' '(' 'budget_in_billions' ')' '...   \n",
       "4  ['SELECT' 'avg' '(' 'num_employees' ')' 'FROM'...   \n",
       "\n",
       "                                 query_toks_no_value  \\\n",
       "0  ['select' 'count' '(' '*' ')' 'from' 'head' 'w...   \n",
       "1  ['select' 'name' ',' 'born_state' ',' 'age' 'f...   \n",
       "2  ['select' 'creation' ',' 'name' ',' 'budget_in...   \n",
       "3  ['select' 'max' '(' 'budget_in_billions' ')' '...   \n",
       "4  ['select' 'avg' '(' 'num_employees' ')' 'from'...   \n",
       "\n",
       "                                       question_toks  \n",
       "0  ['How' 'many' 'heads' 'of' 'the' 'departments'...  \n",
       "1  ['List' 'the' 'name' ',' 'born' 'state' 'and' ...  \n",
       "2  ['List' 'the' 'creation' 'year' ',' 'name' 'an...  \n",
       "3  ['What' 'are' 'the' 'maximum' 'and' 'minimum' ...  \n",
       "4  ['What' 'is' 'the' 'average' 'number' 'of' 'em...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "text_to_sql = load_dataset('csv', data_files={\n",
    "    'train': './data/train.csv',\n",
    "    'test': './data/validation.csv'\n",
    "})\n",
    "train_df = text_to_sql[\"train\"].to_pandas()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_df[\"db_id\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCfhzjbNMTo_"
   },
   "source": [
    "columnê³¼ ê° ë°ì´í„°ì˜ íƒ€ì…ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ë°ì´í„° í•„ë“œ ì„¤ëª…\n",
    "- db_id (string): í•´ë‹¹ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë°ì´í„°ë² ì´ìŠ¤ ì‹ë³„ì\n",
    "- query (string): ì§ˆë¬¸ì— ëŒ€ì‘í•˜ëŠ” SQL ì¿¼ë¦¬\n",
    "- question (string): ì›ë³¸ ì˜ì–´ ìì—°ì–´ ì§ˆë¬¸\n",
    "- query_toks (list): SQL ì¿¼ë¦¬ë¥¼ í† í°í™”í•œ ë¦¬ìŠ¤íŠ¸\n",
    "- query_toks_no_value (list): ê°’ì„ ì œì™¸í•œ SQL ì¿¼ë¦¬ í† í° ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "`.info()` ë§¤ì„œë“œë¥¼ ì´ìš©í•´ì„œ ë°ì´í„°ì˜ íƒ€ì…ê³¼ ê°¯ìˆ˜ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Wmrocn6eMTo_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7000 entries, 0 to 6999\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   db_id                7000 non-null   object\n",
      " 1   query                7000 non-null   object\n",
      " 2   question             7000 non-null   object\n",
      " 3   query_toks           7000 non-null   object\n",
      " 4   query_toks_no_value  7000 non-null   object\n",
      " 5   question_toks        7000 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 328.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‹¤ì œ ë°ì´í„°ë¥¼ ì°ì–´ë³´ë©° ì–´ë–¤ ì‹ìœ¼ë¡œ ë°ì´í„°ê°€ êµ¬ì„±ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "shNhVlUwMTo_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db_id : department_management\n",
      "query : SELECT count(*) FROM head WHERE age  >  56\n",
      "question : How many heads of the departments are older than 56 ?\n",
      "query_toks : ['SELECT' 'count' '(' '*' ')' 'FROM' 'head' 'WHERE' 'age' '>' '56']\n",
      "query_toks_no_value : ['select' 'count' '(' '*' ')' 'from' 'head' 'where' 'age' '>' 'value']\n",
      "question_toks : ['How' 'many' 'heads' 'of' 'the' 'departments' 'are' 'older' 'than' '56'\n",
      " '?']\n"
     ]
    }
   ],
   "source": [
    "# í•œ ì¤„ë§Œ ê°€ì ¸ì˜¤ê¸°\n",
    "for i, row in train_df.iterrows():\n",
    "    for k, v in row.items():\n",
    "        print(k, \":\", v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itJndFrwgob_"
   },
   "source": [
    "ì €í¬ì˜ ëª©í‘œëŠ” ìì—°ì–´(text)ë¥¼ SQLë¡œ ë³€í™˜í•˜ëŠ” Text-to-SQL ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°ˆ ë°ì´í„°ëŠ” ìì—°ì–´ì´ë¯€ë¡œ `question`ì´ ë˜ê³ , ëª¨ë¸ì˜ outputìœ¼ë¡œ ë‚˜ì˜¬ ë°ì´í„°ëŠ” SQLì´ ë˜ì–´ì•¼ í•˜ë¯€ë¡œ `query`ê°€ ë©ë‹ˆë‹¤.\n",
    "\n",
    "`db_id`, `query_toks`, `query_toks_no_value` columnì€ í•™ìŠµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ê³¼ì •ì—ì„œëŠ” í•„ìš”í•  ìˆ˜ ìˆì§€ë§Œ, ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ìƒí™©ì—ì„œëŠ” í•„ìš”í•œ columnì´ ì•„ë‹ˆë¯€ë¡œ í•´ë‹¹ columnì„ ì œê±°í•˜ê³  columnì„ ì¬ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "IH-SQeovgob_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT count(*) FROM head WHERE age  &gt;  56</td>\n",
       "      <td>How many heads of the departments are older th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT name ,  born_state ,  age FROM head ORD...</td>\n",
       "      <td>List the name, born state and age of the heads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT creation ,  name ,  budget_in_billions ...</td>\n",
       "      <td>List the creation year, name and budget of eac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT max(budget_in_billions) ,  min(budget_i...</td>\n",
       "      <td>What are the maximum and minimum budget of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT avg(num_employees) FROM department WHER...</td>\n",
       "      <td>What is the average number of employees of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>SELECT T1.company_name FROM culture_company AS...</td>\n",
       "      <td>What are all the company names that have a boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>SELECT T1.title ,  T3.book_title FROM movie AS...</td>\n",
       "      <td>Show the movie titles and book titles for all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>SELECT T1.title ,  T3.book_title FROM movie AS...</td>\n",
       "      <td>What are the titles of movies and books corres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>SELECT T2.company_name FROM movie AS T1 JOIN c...</td>\n",
       "      <td>Show all company names with a movie directed i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>SELECT T2.company_name FROM movie AS T1 JOIN c...</td>\n",
       "      <td>What are all company names that have a corresp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "0            SELECT count(*) FROM head WHERE age  >  56   \n",
       "1     SELECT name ,  born_state ,  age FROM head ORD...   \n",
       "2     SELECT creation ,  name ,  budget_in_billions ...   \n",
       "3     SELECT max(budget_in_billions) ,  min(budget_i...   \n",
       "4     SELECT avg(num_employees) FROM department WHER...   \n",
       "...                                                 ...   \n",
       "6995  SELECT T1.company_name FROM culture_company AS...   \n",
       "6996  SELECT T1.title ,  T3.book_title FROM movie AS...   \n",
       "6997  SELECT T1.title ,  T3.book_title FROM movie AS...   \n",
       "6998  SELECT T2.company_name FROM movie AS T1 JOIN c...   \n",
       "6999  SELECT T2.company_name FROM movie AS T1 JOIN c...   \n",
       "\n",
       "                                               question  \n",
       "0     How many heads of the departments are older th...  \n",
       "1     List the name, born state and age of the heads...  \n",
       "2     List the creation year, name and budget of eac...  \n",
       "3     What are the maximum and minimum budget of the...  \n",
       "4     What is the average number of employees of the...  \n",
       "...                                                 ...  \n",
       "6995  What are all the company names that have a boo...  \n",
       "6996  Show the movie titles and book titles for all ...  \n",
       "6997  What are the titles of movies and books corres...  \n",
       "6998  Show all company names with a movie directed i...  \n",
       "6999  What are all company names that have a corresp...  \n",
       "\n",
       "[7000 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"query\", \"question\"]\n",
    "\n",
    "train_data = train_df[columns]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQ1fQDltMTo_"
   },
   "source": [
    "ëª¨ë¸ì˜ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ë°ì´í„°ì˜ íŠ¹ì„±ì„ íŒŒì•…í•©ë‹ˆë‹¤.\n",
    "\n",
    "NLPì—ì„œ ì¤‘ìš”í•˜ê²Œ ì²´í¬í•´ì•¼ í•  EDA í•­ëª©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "1. sequence length\n",
    "2. language\n",
    "3. input data domain\n",
    "\n",
    "ìœ„ì˜ ì‚¬í•­ë“¤ì„ ì²´í¬í•´ë´…ì‹œë‹¤.\n",
    "\n",
    "2ë²ˆê³¼ 3ë²ˆì€ ë°ì´í„°ì…‹ì˜ íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ì´ë¯¸ ì²´í¬ê°€ ë©ë‹ˆë‹¤.\n",
    "- language : ì˜ì–´ ë° SQL ì½”ë“œ\n",
    "- input data domain : ë‹¤ì–‘í•œ ì¼ë°˜ í‘œ(table)ì—ì„œ ë½‘ì€ ë°ì´í„°(Open domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "CazDl2MdMTo_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[577, 224, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. sequence length\n",
    "max_sequence = [0, 0, 0]\n",
    "for i, row in train_data.iterrows():\n",
    "    for i, (k, v) in enumerate(row.items()):\n",
    "        max_sequence[i] = max(max_sequence[i], len(str(v)))\n",
    "\n",
    "max_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-INGjEM_MTpA"
   },
   "source": [
    "`max_length`ê°€ ëª¨ë¸ì˜ `max_sequence_length`ë¥¼ ë„˜ì§€ ì•Šì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒí•©ë‹ˆë‹¤.\n",
    "\n",
    "<blockquote>\n",
    "<b>ğŸ§  ëª¨ë¸ ì…ë ¥ì€ tokenì´ë‹ˆê¹Œ token ê¸¸ì´ë¥¼ ì¸¡ì •í•´ì•¼ í•˜ëŠ”ê±° ì•„ë‹Œê°€ìš”?</b><br>\n",
    "ë§ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ í˜„ì¬ ì–´ë–¤ ëª¨ë¸ì„ ì‚¬ìš©í• ì§€ ì •í•´ì§€ì§€ ì•Šì€ ìƒí™©ì—ì„œëŠ” token ê¸¸ì´ë¥¼ ì¸¡ì •í•˜ê¸°ëŠ” ì–´ë µìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ëŒ€ëµì ì¸ ê¸¸ì´ë¥¼ ë³´ê³  ëª¨ë¸ì´ ê²°ì •ë˜ë©´ token ê¸¸ì´ë¥¼ ë‹¤ì‹œ ì¸¡ì •í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "</blockquote>\n",
    "\n",
    "ì´ì œë¶€í„° ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜µì‹œë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XL9itwo5MTpA"
   },
   "source": [
    "# 2. base ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "- í•™ìŠµ ëª©í‘œ : base ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.\n",
    "- í•™ìŠµ ê°œë… : base ëª¨ë¸\n",
    "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
    "    - base ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    - í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osPVNyM3MTpA"
   },
   "source": [
    "ì‚¬ìš©í•  ëª¨ë¸ì€ [naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B](https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B)ì…ë‹ˆë‹¤.\n",
    "\n",
    "í˜„ì¬ 6GBí•˜ì˜ VRAMì—ì„œ í•™ìŠµì´ ê°€ëŠ¥í•œ ëª¨ë¸ì€ ìœ„ì˜ ëª¨ë¸ì…ë‹ˆë‹¤. ë˜í•œ, ë„¤ì´ë²„ì—ì„œ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ê³µê°œí•œ ëª¨ë¸ì´ë¯€ë¡œ, ëˆ„êµ¬ë‚˜ ì‚¬ìš©ì´ ê°€ëŠ¥í•œ ëª¨ë¸ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYVIf7eNMTpA"
   },
   "source": [
    "ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7fxGvCckMTpA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "if tokenizer.pad_token is None: # pad_token ì„¤ì •ì´ ë˜ì–´ìˆì§€ ì•ŠëŠ” ê²½ìš°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWnvZJVogocA"
   },
   "source": [
    "ëª¨ë¸ì˜ max_sequence_lengthë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "max_position_embeddingsì˜ ê¸¸ì´ëŠ” position embeddingsì˜ ê¸¸ì´ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "position embeddingsëŠ” ì…ë ¥ í† í°ì— ìˆœì„œ ì •ë³´ë¥¼ ë„£ëŠ” ì„ë² ë”©ì´ë¯€ë¡œ í•´ë‹¹ ì°¨ì›ì´ ì‹¤ì œ ì…ë ¥ í† í°ì˜ ê¸¸ì´ì™€ ë™ì¼í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AMR9MTYDgocA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length of model: 8192\n",
      "Max sequence length: [201, 50, 0]\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = model.config.max_position_embeddings\n",
    "max_sequence = [0, 0, 0]\n",
    "for i, row in train_data.iterrows():\n",
    "    for i, (k, v) in enumerate(row.items()):\n",
    "        max_sequence[i] = max(max_sequence[i], len(tokenizer(str(v))[\"input_ids\"]))\n",
    "\n",
    "print(\"Max sequence length of model:\", max_sequence_length)\n",
    "print(\"Max sequence length:\", max_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OENkJoTkgocB"
   },
   "source": [
    "8192ì˜ ê¸¸ì´ë¼ë©´ í† í¬ë‚˜ì´ì§•ì„ í•œ ì´í›„ì˜ `max_length`ì¸ 201 + 50 ë³´ë‹¤ í›¨ì”¬ í¬ê¸° ë•Œë¬¸ì— ì¶©ë¶„íˆ ì—¬ìœ ë¡­ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8khDfofMTpB"
   },
   "source": [
    "# 3. Text-to-SQL task ë°ì´í„° ì „ì²˜ë¦¬\n",
    "- í•™ìŠµ ëª©í‘œ : chat í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ í•  ìˆ˜ ìˆë‹¤.\n",
    "- í•™ìŠµ ê°œë… : ë°ì´í„° ì „ì²˜ë¦¬\n",
    "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
    "    - apply_chat_templateìœ¼ë¡œ ë°ì´í„° ì „ì²˜ë¦¬í•˜ê¸°\n",
    "    - datasetsë¥¼ ì´ìš©í•˜ì—¬ Datasets í˜•ì‹ìœ¼ë¡œ ë³€ê²½í•˜ê¸°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ptz5jjWnMTpB"
   },
   "source": [
    "í—ˆê¹…í˜ì´ìŠ¤ tokenizerì—ì„œëŠ” jinja2 í¬ë§·ì˜ `chat_template`ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "ë³´í†µ LLMì„ ì œê³µí•˜ëŠ” íšŒì‚¬, ëª¨ë¸ë§ˆë‹¤ `chat_template`ì´ ë‹¤ë¦…ë‹ˆë‹¤. ë˜í•œ, ìµœê·¼ì—ëŠ” `chat_template`ì„ ëŒ€ë¶€ë¶„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë”°ë¼ì„œ, `chat_template`ì„ í™•ì¸í•˜ê³  `apply_chat_template` ë§¤ì„œë“œë¥¼ ì´ìš©í•´ì„œ ì–´ë–»ê²Œ ì ìš©ì´ ë˜ëŠ”ì§€ í™•ì¸í•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CvkxSQrZMTpB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== chat template ì‚¬ìš© ê°€ëŠ¥ ===\n",
      "\n",
      "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n"
     ]
    }
   ],
   "source": [
    "if tokenizer.chat_template:\n",
    "    print(\"=== chat template ì‚¬ìš© ê°€ëŠ¥ ===\\n\")\n",
    "    print(tokenizer.chat_template)\n",
    "else:\n",
    "    print(\"=== chat template ì‚¬ìš© ë¶ˆê°€ëŠ¥ ===\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSjDuehkMTpB"
   },
   "source": [
    "Jinja2 í¬ë§·ì´ ì´ìƒí•˜ê¸´ í•˜ì§€ë§Œ ì½”ë“œë¥¼ ì–´ëŠì •ë„ ì´í•´í•˜ì‹œëŠ” ë¶„ë“¤ì´ë¼ë©´ ì´ê²Œ ì–´ë–¤ ì˜ë¯¸ì¸ì§€ë¥¼ ëŒ€ì¶© ìœ ì¶”í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "```jinja\n",
    "{% for message in messages %}\n",
    "```\n",
    "ì–´ë– í•œ `iterable` ê°ì²´ë¥¼ `for loop`ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ë´ì„œëŠ” `list` ë“±ì˜ ê°ì²´ë¡œ ë„£ì–´ì¤˜ì•¼ í• ê±° ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "```jinja\n",
    "{{'<|im_start|>' + message['role'] + '' + message['content'] + '<|im_end|>' + ''}}\n",
    "```\n",
    "\n",
    "`message` ë‚´ì— ë³´ë©´ `role`ê³¼ `content`ë¼ëŠ” í‚¤ê°’ì´ í•„ìš”í•œ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œ `dictionary` ë“±ì˜ ê°ì²´ë¥¼ ì‚¬ìš©í•˜ë©´ ë ê±° ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë˜í•œ, ì•ë’¤ì— `<|im_start|>`, `<|im_end|>`ì™€ ê°™ì€ ìŠ¤í˜ì…œ í† í°ì´ ë¶™ëŠ” ê²ƒì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë¶€ë¶„ì€ ì €í¬ê°€ ê±´ë“¤ í•„ìš” ì—†ì´ ì•Œì•„ì„œ ìƒì„±í•´ì¤ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2DRPXntMTpB"
   },
   "source": [
    "`apply_chat_template`ì˜ ì…ë ¥ìœ¼ë¡œ ë„£ê¸° ìœ„í•´ì„œëŠ” chat(conversations) í˜•ì‹ì„ ì§€ì¼œì„œ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì¤˜ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê¸°ì¡´ì— ë¶ˆëŸ¬ì˜¨ ë°ì´í„°í”„ë ˆì„ì„ chat í˜•ì‹ìœ¼ë¡œ ë§Œë“¤ê³  `apply_chat_template`ì„ ì ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dCUsJy-xMTpB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'How many heads of the departments are older than 56 ?'}, {'role': 'assistant', 'content': 'SELECT count(*) FROM head WHERE age  >  56'}]\n",
      "\n",
      "<|im_start|>user\n",
      "How many heads of the departments are older than 56 ?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "SELECT count(*) FROM head WHERE age  >  56<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµìš© ë°ì´í„° ì „ì²˜ë¦¬\n",
    "\n",
    "example = train_df[columns].iloc[0]\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": example[\"question\"]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": example[\"query\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(messages)\n",
    "print()\n",
    "chat = tokenizer.apply_chat_template(messages, tokenize = False, add_generation_prompt = False)\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mik1sNt-MTpB"
   },
   "source": [
    "ë³´ì‹œëŠ” ë°”ì™€ ê°™ì´ ëª¨ë¸ì˜ ì…ë ¥ì— ë§ê²Œ í˜•ì‹ì„ ë§ì¶°ì„œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ì£¼ëŠ” ê²ƒì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì£¼ì˜í•  ì ì´ í¬ê²Œ 2ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "1. `assistant`ëŠ” ì •ë‹µì´ê¸° ë•Œë¬¸ì— í•™ìŠµì—ì„œë§Œ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì£¼ê³  ì¶”ë¡ ì—ì„œëŠ” ë„£ì–´ì¤˜ì„œëŠ” ì•ˆë©ë‹ˆë‹¤.\n",
    "2. `add_generation_prompt=False`ëŠ” `assistant`ê°€ ë“¤ì–´ê°”ê¸° ë•Œë¬¸ì— `False`ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ì¶”ë¡ ìš©ì´ë¼ë©´ `True`ë¡œ ì„¤ì •í•´ì£¼ì…”ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gGhsfqgiMTpB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "How many heads of the departments are older than 56 ?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ì¶”ë¡ ìš© ë°ì´í„° ì „ì²˜ë¦¬\n",
    "chat_inference = tokenizer.apply_chat_template(messages[:-1], tokenize = False, add_generation_prompt = True)\n",
    "print(chat_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iImj1ZdsMTpB"
   },
   "source": [
    "ì¶”ë¡ ìš© ë°ì´í„°ë¥¼ í™•ì¸í•´ë³´ì‹œë©´\n",
    "\n",
    "`SELECT * FROM players;<|im_end|>`\n",
    "\n",
    "ì´ ì‚¬ë¼ì§„ ê²ƒì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìœ ì˜í•  ì ì€\n",
    "1. ëª¨ë¸ì´ ì •ë‹µìœ¼ë¡œ ìƒì„±í•  í…ìŠ¤íŠ¸ : `SELECT * FROM players;`\n",
    "2. EOS ìŠ¤í˜ì…œ í† í° : `<|im_end|>`\n",
    "\n",
    "ë‘ê°€ì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆëŠ” `assistant` ë¶€ë¶„ì„ í•™ìŠµì— ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lglZq-BNMTpC"
   },
   "source": [
    "ì´ì œ ëª¨ë¸ ì…ë ¥ìœ¼ë¡œ ë„£ê¸° ìœ„í•´ì„œ ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë°ì´í„°í”„ë ˆì„ì— ìˆëŠ” ë°ì´í„°ë¥¼ êº¼ë‚´ì„œ `Dataset` ê°ì²´ë¡œ ë³€í™˜í•˜ëŠ” ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8ej6uwC7MTpC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a text to SQL query translator. Users will ask you questions in English and you will generate a SQL query.', 'role': 'system'}, {'content': \"Given the <USER_QUERY>, generate the corresponding SQL command to retrieve the desired data, considering the query's syntax, semantics, and schema constraints.\\n\\n<USER_QUERY>\\nHow many heads of the departments are older than 56 ?\\n</USER_QUERY>\", 'role': 'user'}, {'content': 'SELECT count(*) FROM head WHERE age  >  56', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "system_prompt = \"\"\"You are a text to SQL query translator. Users will ask you questions in English and you will generate a SQL query.\"\"\"\n",
    "user_prompt = \"\"\"Given the <USER_QUERY>, generate the corresponding SQL command to retrieve the desired data, considering the query's syntax, semantics, and schema constraints.\n",
    "\n",
    "<USER_QUERY>\n",
    "{question}\n",
    "</USER_QUERY>\"\"\"\n",
    "\n",
    "def convert_to_conversation(examples):\n",
    "    train_data = []\n",
    "    for i in range(len(examples)):\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt.format(question=examples[\"question\"][i])\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": examples['query'][i]\n",
    "            }\n",
    "        ]\n",
    "        train_data.append(\n",
    "            {\n",
    "                \"messages\": messages,\n",
    "            }\n",
    "        )\n",
    "    return train_data\n",
    "\n",
    "train_data_list = convert_to_conversation(train_data)\n",
    "train_dataset = datasets.Dataset.from_list(train_data_list)\n",
    "print(train_dataset[\"messages\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DT4K6Y5yxuF5"
   },
   "source": [
    "ë³´í†µ ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ ì‚¬ìš©í•˜ëŠ” labelsëŠ” inputsì™€ ë™ì¼í•©ë‹ˆë‹¤.\n",
    "\n",
    "(ëª¨ë¸ì€ ë‚´ë¶€ì ìœ¼ë¡œ labelsë¥¼ í•œ ì¹¸ ì˜¤ë¥¸ìª½ìœ¼ë¡œ shiftí•œ í›„ Cross-Entropy lossë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ëŠ” ë‹¤ìŒ í† í° ì˜ˆì¸¡(next token prediction)ê³¼ ê°™ì€ auto-regressive ë¶„ë¥˜ ì‘ì—…ì—ì„œ í‘œì¤€ ë°©ì‹ì…ë‹ˆë‹¤.)\n",
    "\n",
    "ë”°ë¼ì„œ ì „ì²˜ë¦¬ëœ ìƒ˜í”Œì€ ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœê°€ ë©ë‹ˆë‹¤:\n",
    "```python\n",
    "{\n",
    "    \"input_ids\": instruction + model response(assistant),\n",
    "    \"labels\": instruction + model response(assistant)\n",
    "}  # HF ëª¨ë¸ì´ shift +1 ì²˜ë¦¬ë¥¼ ë‚´ë¶€ì ìœ¼ë¡œ ìˆ˜í–‰\n",
    "```\n",
    "\n",
    "- instruction : ëª¨ë¸ì—ê²Œ ì…ë ¥ìœ¼ë¡œ ë„£ì„ ì§€ì‹œì‚¬í•­ (ì‹¤ì œ Userë“¤ì´ ì…ë ¥ìœ¼ë¡œ ë„£ì„ í…ìŠ¤íŠ¸)\n",
    "- model response : instructionì— ëŒ€í•œ ëª¨ë¸ì˜ ì‘ë‹µ (`assistant`ì™€ ë™ì¼)\n",
    "\n",
    "í•˜ì§€ë§Œ ìš°ë¦¬ê°€ í•˜ë ¤ëŠ” ì‘ì—…ì€ instruction ë¶€ë¶„ì„ -100ìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì™œëƒí•˜ë©´ ì €í¬ëŠ” ëª¨ë¸ì´ ì •ë‹µ(`assistant`) ë¶€ë¶„ë§Œ í•™ìŠµì„ í•˜ë„ë¡ í•˜ê³  ì‹¶ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"input_ids\": instruction + model response(assistant),\n",
    "    \"labels\": [-100]*len(instruction) + model response(assistant)\n",
    "}\n",
    "```\n",
    "\n",
    "ì´ë ‡ê²Œ í•˜ë©´ Cross-Entropy í•¨ìˆ˜ì— instruction í† í°ì€ ë¬´ì‹œ(ignore) í•˜ë¼ê³  ì•Œë ¤ì£¼ëŠ” ì…ˆì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ assistant ë¶€ë¶„ë§Œ í•™ìŠµì„ í•˜ë„ë¡ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì˜ˆë¥¼ ë“¤ì–´,\n",
    "\n",
    "```\n",
    "<|im_start|>system\n",
    "You are a text to SQL query translator. Users will ask you questions in English and you will generate a SQL query.<|im_end|>\n",
    "<|im_start|>user\n",
    "Given the <USER_QUERY>, generate the corresponding SQL command to retrieve the desired data, considering the query's syntax, semantics, and schema constraints.\n",
    "\n",
    "<USER_QUERY>\n",
    "How many heads of the departments are older than 56 ?\n",
    "</USER_QUERY><|im_end|>\n",
    "<|im_start|>assistant\n",
    "SELECT count(*) FROM head WHERE age  >  56<|im_end|>\n",
    "```\n",
    "\n",
    "ìœ„ì—ì„œ í•™ìŠµí•´ì•¼ í•  ë¶€ë¶„(ì •ë‹µ ë¼ë²¨)ì€\n",
    "```\n",
    "SELECT count(*) FROM head WHERE age  >  56<|im_end|>\n",
    "```\n",
    "ì´ ë¶€ë¶„ì´ë¯€ë¡œ, ë‚˜ë¨¸ì§€ ë¶€ë¶„ë“¤ì€ -100ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬ë¥¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "aLOWwRq8wSwz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 7000\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_train_data(examples, tokenizer):\n",
    "    messages = examples[\"messages\"]\n",
    "    label_message = messages[-1][\"content\"]\n",
    "    label_input_ids = tokenizer.encode(\n",
    "        label_message, add_special_tokens=False, return_tensors=\"pt\"\n",
    "    ).squeeze(0)\n",
    "\n",
    "    prompt_input_ids = tokenizer.apply_chat_template(\n",
    "        messages[:2], add_generation_prompt=False, tokenize=True, return_tensors=\"pt\"\n",
    "    ).squeeze(0)\n",
    "\n",
    "    response_start_template_ids = tokenizer.encode(\"<|im_start|>assistant\", return_tensors=\"pt\")[0]\n",
    "\n",
    "    input_ids = torch.cat(\n",
    "        [\n",
    "            prompt_input_ids,\n",
    "            response_start_template_ids,\n",
    "            label_input_ids,\n",
    "            torch.tensor([tokenizer.eos_token_id]),\n",
    "        ],\n",
    "        dim=0,\n",
    "    )\n",
    "    attention_mask = torch.ones(len(input_ids), dtype=torch.int64)\n",
    "    labels = torch.cat(\n",
    "        [\n",
    "            torch.tensor(\n",
    "                [-100] * (len(input_ids) - len(label_input_ids) - 1)\n",
    "            ),  # prompt + label_start_template\n",
    "            label_input_ids,  # label\n",
    "            torch.tensor([tokenizer.eos_token_id]),  # [EOS]\n",
    "        ],\n",
    "        dim=0,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "    )\n",
    "\n",
    "datasets.disable_progress_bar()\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda x: convert_train_data(x, tokenizer),\n",
    "    batched=False,\n",
    "    num_proc=1,\n",
    "    remove_columns=train_dataset.column_names  # ì›ë³¸ ì»¬ëŸ¼ ì œê±°í•˜ê³  ìƒˆ ì»¬ëŸ¼ë§Œ ë‚¨ê¹€\n",
    ")\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWTQ8p6T0Kx8"
   },
   "source": [
    "1. input_ids â€“ í† í¬ë‚˜ì´ì¦ˆëœ ì‹œí€€ìŠ¤ ë°ì´í„°\n",
    "- í† í¬ë‚˜ì´ì €(tokenizer)ê°€ í…ìŠ¤íŠ¸ë¥¼ **ì„œë¸Œì›Œë“œ ë‹¨ìœ„(subword units)**ë¡œ ë¶„í• í•˜ê³ , ì´ë¥¼ **ì–´íœ˜ ì‚¬ì „(vocabulary)**ì— ì •ì˜ëœ **í† í° ì¸ë±ìŠ¤(token index)**ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "- ì´ ì‹œí€€ìŠ¤ê°€ Transformer ëª¨ë¸ì˜ **ì„ë² ë”© ë ˆì´ì–´(embedding layer)**ì— ì…ë ¥ë˜ì–´, ê° ì •ìˆ˜ê°€ ê³ ì°¨ì› ë²¡í„°ë¡œ ì„ë² ë”©ë©ë‹ˆë‹¤.\n",
    "\n",
    "2. attention_mask â€“ ì‹œí€€ìŠ¤ ë§ˆìŠ¤í‚¹ í…ì„œ\n",
    "- TransformerëŠ” ì¼ë°˜ì ìœ¼ë¡œ ê³ ì •ëœ ìµœëŒ€ ê¸¸ì´(max sequence length) ì…ë ¥ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- ì‹¤ì œ ì…ë ¥ ê¸¸ì´ê°€ ì§§ìœ¼ë©´ íŒ¨ë”©(padding)ì„ ì¶”ê°€í•´ ë§ì¶”ëŠ”ë°, ì´ë•Œ íŒ¨ë”© í† í°ì€ self-attention ì—°ì‚°ì—ì„œ ë¬´ì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- attention_maskëŠ” ê°™ì€ ê¸¸ì´ì˜ ë°”ì´ë„ˆë¦¬ ë²¡í„°ë¡œ,\n",
    "  - ì‹¤ì œ í† í° ìœ„ì¹˜ â†’ 1\n",
    "  - íŒ¨ë”© í† í° ìœ„ì¹˜ â†’ 0\n",
    "- ì´ ë§ˆìŠ¤í¬ëŠ” ì–´í…ì…˜ ìŠ¤ì½”ì–´(attention score) ê³„ì‚° ì‹œ ì†Œí”„íŠ¸ë§¥ìŠ¤ ì´ì „ì— ë§¤ìš° ì‘ì€ ìŒìˆ˜(âˆ’âˆ)ë¥¼ ë”í•´, íŒ¨ë”© ìœ„ì¹˜ì˜ ê¸°ì—¬ë„ë¥¼ ì™„ì „íˆ ì œê±°í•©ë‹ˆë‹¤.\n",
    "\n",
    "3. labels â€“ í•™ìŠµ ëŒ€ìƒ(target) ì‹œí€€ìŠ¤\n",
    "- labelsëŠ” **ëª¨ë¸ì˜ ì¶œë ¥ ë¡œì§“(logits)**ê³¼ ë¹„êµí•  íƒ€ê²Ÿ ì‹œí€€ìŠ¤ì…ë‹ˆë‹¤.\n",
    "- ì–¸ì–´ ëª¨ë¸ í•™ìŠµ ì‹œ auto-regressive(next-token prediction) ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•˜ë¯€ë¡œ, labelsëŠ” ë³´í†µ input_idsì™€ ë™ì¼í•˜ì§€ë§Œ ì†ì‹¤ ê³„ì‚°ì—ì„œ ì œì™¸í•  í† í° ìœ„ì¹˜ë¥¼ -100ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•©ë‹ˆë‹¤.\n",
    "- ì´ë ‡ê²Œ í•˜ë©´ Cross-Entropy Loss ê³„ì‚° ì‹œ ë¬´ì‹œëœ ìœ„ì¹˜ëŠ” loss=0ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Qx9Ai-ynz63S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids :  [100272, 9125, 198, 2675, 527, 264, 1495, 311, 8029, 3319, 46588, 13, 14969, 690, 2610, 499, 4860, 304, 6498, 323, 499, 690, 7068, 264, 8029, 3319, 13, 100273, 198, 100272, 882, 198, 22818, 279, 366, 6584, 32685, 8226, 7068, 279, 12435, 8029, 3290, 311, 17622, 279, 12974, 828, 11, 13126, 279, 3319, 596, 20047, 11, 53794, 11, 323, 11036, 17413, 382, 27, 6584, 32685, 397, 4438, 1690, 14971, 315, 279, 26280, 527, 9191, 1109, 220, 3487, 18072, 524, 6584, 32685, 29, 100273, 198, 100272, 78191, 4963, 1797, 29771, 4393, 2010, 5401, 4325, 220, 871, 220, 220, 3487, 100275]\n",
      "attention_mask :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "labels :  [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 4963, 1797, 29771, 4393, 2010, 5401, 4325, 220, 871, 220, 220, 3487, 100275]\n"
     ]
    }
   ],
   "source": [
    "print(\"input_ids : \", train_dataset[\"input_ids\"][0])\n",
    "print(\"attention_mask : \", train_dataset[\"attention_mask\"][0])\n",
    "print(\"labels : \", train_dataset[\"labels\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. base model ì„±ëŠ¥ ì¸¡ì •\n",
    "- í•™ìŠµ ëª©í‘œ : ko_text2sql ë°ì´í„°ì…‹ì„ ì´ìš©í•´ì„œ base modelì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•  ìˆ˜ ìˆë‹¤.\n",
    "- í•™ìŠµ ê°œë… : metric, \n",
    "- ì§„í–‰í•˜ëŠ” ì‹¤ìŠµ ìš”ì•½\n",
    "    - í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    - ì„±ëŠ¥ ì¸¡ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model í•™ìŠµì„ í•˜ê¸° ì „ì— base modelì˜ ì„±ëŠ¥ì´ ì–¼ë§ˆì¸ì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ì„œëŠ” 2ê°€ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "1. ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹\n",
    "2. ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ ì§€í‘œ\n",
    "\n",
    "ko_text2sqlì— ìˆëŠ” test ë°ì´í„°ì…‹ì„ í™œìš©í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "      <th>query_toks</th>\n",
       "      <th>query_toks_no_value</th>\n",
       "      <th>question_toks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concert_singer</td>\n",
       "      <td>SELECT count(*) FROM singer</td>\n",
       "      <td>How many singers do we have?</td>\n",
       "      <td>['SELECT' 'count' '(' '*' ')' 'FROM' 'singer']</td>\n",
       "      <td>['select' 'count' '(' '*' ')' 'from' 'singer']</td>\n",
       "      <td>['How' 'many' 'singers' 'do' 'we' 'have' '?']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>concert_singer</td>\n",
       "      <td>SELECT count(*) FROM singer</td>\n",
       "      <td>What is the total number of singers?</td>\n",
       "      <td>['SELECT' 'count' '(' '*' ')' 'FROM' 'singer']</td>\n",
       "      <td>['select' 'count' '(' '*' ')' 'from' 'singer']</td>\n",
       "      <td>['What' 'is' 'the' 'total' 'number' 'of' 'sing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>concert_singer</td>\n",
       "      <td>SELECT name ,  country ,  age FROM singer ORDE...</td>\n",
       "      <td>Show name, country, age for all singers ordere...</td>\n",
       "      <td>['SELECT' 'name' ',' 'country' ',' 'age' 'FROM...</td>\n",
       "      <td>['select' 'name' ',' 'country' ',' 'age' 'from...</td>\n",
       "      <td>['Show' 'name' ',' 'country' ',' 'age' 'for' '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concert_singer</td>\n",
       "      <td>SELECT name ,  country ,  age FROM singer ORDE...</td>\n",
       "      <td>What are the names, countries, and ages for ev...</td>\n",
       "      <td>['SELECT' 'name' ',' 'country' ',' 'age' 'FROM...</td>\n",
       "      <td>['select' 'name' ',' 'country' ',' 'age' 'from...</td>\n",
       "      <td>['What' 'are' 'the' 'names' ',' 'countries' ',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>concert_singer</td>\n",
       "      <td>SELECT avg(age) ,  min(age) ,  max(age) FROM s...</td>\n",
       "      <td>What is the average, minimum, and maximum age ...</td>\n",
       "      <td>['SELECT' 'avg' '(' 'age' ')' ',' 'min' '(' 'a...</td>\n",
       "      <td>['select' 'avg' '(' 'age' ')' ',' 'min' '(' 'a...</td>\n",
       "      <td>['What' 'is' 'the' 'average' ',' 'minimum' ','...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            db_id                                              query  \\\n",
       "0  concert_singer                        SELECT count(*) FROM singer   \n",
       "1  concert_singer                        SELECT count(*) FROM singer   \n",
       "2  concert_singer  SELECT name ,  country ,  age FROM singer ORDE...   \n",
       "3  concert_singer  SELECT name ,  country ,  age FROM singer ORDE...   \n",
       "4  concert_singer  SELECT avg(age) ,  min(age) ,  max(age) FROM s...   \n",
       "\n",
       "                                            question  \\\n",
       "0                       How many singers do we have?   \n",
       "1               What is the total number of singers?   \n",
       "2  Show name, country, age for all singers ordere...   \n",
       "3  What are the names, countries, and ages for ev...   \n",
       "4  What is the average, minimum, and maximum age ...   \n",
       "\n",
       "                                          query_toks  \\\n",
       "0     ['SELECT' 'count' '(' '*' ')' 'FROM' 'singer']   \n",
       "1     ['SELECT' 'count' '(' '*' ')' 'FROM' 'singer']   \n",
       "2  ['SELECT' 'name' ',' 'country' ',' 'age' 'FROM...   \n",
       "3  ['SELECT' 'name' ',' 'country' ',' 'age' 'FROM...   \n",
       "4  ['SELECT' 'avg' '(' 'age' ')' ',' 'min' '(' 'a...   \n",
       "\n",
       "                                 query_toks_no_value  \\\n",
       "0     ['select' 'count' '(' '*' ')' 'from' 'singer']   \n",
       "1     ['select' 'count' '(' '*' ')' 'from' 'singer']   \n",
       "2  ['select' 'name' ',' 'country' ',' 'age' 'from...   \n",
       "3  ['select' 'name' ',' 'country' ',' 'age' 'from...   \n",
       "4  ['select' 'avg' '(' 'age' ')' ',' 'min' '(' 'a...   \n",
       "\n",
       "                                       question_toks  \n",
       "0      ['How' 'many' 'singers' 'do' 'we' 'have' '?']  \n",
       "1  ['What' 'is' 'the' 'total' 'number' 'of' 'sing...  \n",
       "2  ['Show' 'name' ',' 'country' ',' 'age' 'for' '...  \n",
       "3  ['What' 'are' 'the' 'names' ',' 'countries' ',...  \n",
       "4  ['What' 'is' 'the' 'average' ',' 'minimum' ','...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = text_to_sql[\"test\"].to_pandas()\n",
    "print(len(test_df))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í•™ìŠµ ë°ì´í„°ì…‹ê³¼ ë™ì¼í•œ ì„±ê²©ì„ ê°€ì§„ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë”°ë¼ì„œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ë„ ë™ì¼í•˜ê²Œ í•„ìš”í•œ columnë§Œ ë‚¨ê¸°ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT count(*) FROM singer</td>\n",
       "      <td>How many singers do we have?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT count(*) FROM singer</td>\n",
       "      <td>What is the total number of singers?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT name ,  country ,  age FROM singer ORDE...</td>\n",
       "      <td>Show name, country, age for all singers ordere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SELECT name ,  country ,  age FROM singer ORDE...</td>\n",
       "      <td>What are the names, countries, and ages for ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SELECT avg(age) ,  min(age) ,  max(age) FROM s...</td>\n",
       "      <td>What is the average, minimum, and maximum age ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>SELECT Citizenship FROM singer WHERE Birth_Yea...</td>\n",
       "      <td>What are the citizenships that are shared by s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>SELECT count(*) FROM Other_Available_Features</td>\n",
       "      <td>How many available features are there in total?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>SELECT T2.feature_type_name FROM Other_Availab...</td>\n",
       "      <td>What is the feature type name of feature AirCon?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>SELECT T2.property_type_description FROM Prope...</td>\n",
       "      <td>Show the property type descriptions of propert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>SELECT property_name FROM Properties WHERE pro...</td>\n",
       "      <td>What are the names of properties that are eith...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1034 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "0                           SELECT count(*) FROM singer   \n",
       "1                           SELECT count(*) FROM singer   \n",
       "2     SELECT name ,  country ,  age FROM singer ORDE...   \n",
       "3     SELECT name ,  country ,  age FROM singer ORDE...   \n",
       "4     SELECT avg(age) ,  min(age) ,  max(age) FROM s...   \n",
       "...                                                 ...   \n",
       "1029  SELECT Citizenship FROM singer WHERE Birth_Yea...   \n",
       "1030      SELECT count(*) FROM Other_Available_Features   \n",
       "1031  SELECT T2.feature_type_name FROM Other_Availab...   \n",
       "1032  SELECT T2.property_type_description FROM Prope...   \n",
       "1033  SELECT property_name FROM Properties WHERE pro...   \n",
       "\n",
       "                                               question  \n",
       "0                          How many singers do we have?  \n",
       "1                  What is the total number of singers?  \n",
       "2     Show name, country, age for all singers ordere...  \n",
       "3     What are the names, countries, and ages for ev...  \n",
       "4     What is the average, minimum, and maximum age ...  \n",
       "...                                                 ...  \n",
       "1029  What are the citizenships that are shared by s...  \n",
       "1030    How many available features are there in total?  \n",
       "1031   What is the feature type name of feature AirCon?  \n",
       "1032  Show the property type descriptions of propert...  \n",
       "1033  What are the names of properties that are eith...  \n",
       "\n",
       "[1034 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_df[columns]\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ë‹µ : SELECT count(*) FROM singer\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "\n",
    "test_input = [\n",
    "    {'role': 'system', 'content': system_prompt},\n",
    "    {'role': 'user', 'content': user_prompt.format(question=test_data[\"question\"][text_idx])},\n",
    "]\n",
    "print(\"ì •ë‹µ :\", test_data[\"query\"][text_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ base modelì˜ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•´ ì¸¡ì • metricì„ ì„¤ì •í•©ë‹ˆë‹¤. ì €í¬ê°€ ì‚¬ìš©í•  metricì€ `execution accuracy`ì…ë‹ˆë‹¤.\n",
    "\n",
    "text to sql taskì˜ ê²½ìš°, ìì—°ì–´ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ modelì´ sqlë¬¸ì„ ì¶œë ¥í•˜ëŠ” ê²ƒì´ë¯€ë¡œ, ëª¨ë¸ì˜ response ê²°ê³¼ë¬¼ì´ ì‹¤ì œ sqlë¬¸ì´ ì˜ ë™ì‘í•˜ëŠ”ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€ë¥¼ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ í‰ê°€ ë°©ì‹ì€ sqlë¬¸ì€ ë‹¤ë¥´ë”ë¼ë„ ì˜ë„ëŒ€ë¡œ ì‹¤í–‰ì´ ë˜ì—ˆë‹¤ë©´ ì •ë‹µì´ ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì •í™•íˆ SQLë¬¸ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í‰ê°€í•˜ëŠ” exact match ë³´ë‹¤ ìœ ì—°í•œ ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŸ¬í•œ metricì€ ì‹¤ì œë¡œ databaseì— ë“¤ì–´ìˆëŠ” ë°ì´í„°ë¥¼ sqlë¬¸ì„ ì‹¤í–‰í–ˆì„ ë•Œ, ì˜ë„í•œ sqlë¬¸ì´ ë™ì‘í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. ì•„ë˜ ì˜ˆì‹œ ë°ì´í„°ë¡œ ì§„í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 10th prediction\n",
      "Evaluating 20th prediction\n",
      "Evaluating 30th prediction\n",
      "Evaluating 40th prediction\n",
      "Evaluating 50th prediction\n",
      "Evaluating 60th prediction\n",
      "Evaluating 70th prediction\n",
      "Evaluating 80th prediction\n",
      "Evaluating 90th prediction\n",
      "Evaluating 100th prediction\n",
      "Evaluating 110th prediction\n",
      "Evaluating 120th prediction\n",
      "Evaluating 130th prediction\n",
      "                     easy                 medium               hard                 extra                all                  joint_all           \n",
      "count                146                  106                  38                   32                   322                  132                 \n",
      "=====================   EXECUTION ACCURACY     =====================\n",
      "execution            0.164                0.038                0.000                0.031                0.090                0.008               \n",
      "\n",
      "\n",
      "                     turn 1               turn 2               turn 3               turn 4               turn > 4            \n",
      "count                132                  132                  58                   0                    0                   \n",
      "=====================   TURN EXECUTION ACCURACY     =====================\n",
      "execution            0.182                0.030                0.017                0.000                0.000               \n"
     ]
    }
   ],
   "source": [
    "!cd test-suite-sql-eval-master && python evaluation.py --gold evaluation_examples/gold.txt --pred evaluation_examples/predict.txt --db database/ --etype exec --plug_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜ˆì‹œ ê²°ê³¼ë¬¼ì„ ë³´ì‹œë©´ allì´ executionì—ì„œ 0.090 ì¸ ê²ƒì„ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¬¼ì„ 100ê°œë¥¼ ì‹¤í–‰í–ˆë‹¤ë©´ 9ê°œë§Œ ì˜ë„í•œëŒ€ë¡œ ì‹¤í–‰ë˜ì—ˆë‹¤ëŠ” ê²ƒê³¼ ë™ì¼í•œ ì˜ë¯¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆì—ëŠ” í•™ìŠµí•˜ì§€ ì•Šì€ base ëª¨ë¸ì„ ê°€ì§€ê³  ì–¼ë§ˆë‚˜ ì„±ëŠ¥ì´ ë‚˜ì˜¤ê³  ìˆëŠ”ì§€ ì¸¡ì •í•´ë³´ê² ìŠµë‹ˆë‹¤. ëª¨ë¸ ì¶”ë¡ ì„ ëŒë¦¬ëŠ”ë° ì‹œê°„ì´ ê±¸ë¦¬ë¯€ë¡œ test ë°ì´í„° ì¤‘ì—ì„œ 100ê°œë§Œ ë¯¸ë¦¬ ëª¨ë¸ ì¶”ë¡ ì„ ì‹¤í–‰í–ˆìŠµë‹ˆë‹¤. ë”°ë¡œ ì‹¤í–‰ì„ í•´ë³´ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´ `python inference --pred_file_name base_model_predict.txt`ë¡œ ì‹¤í–‰í•˜ë©´ base modelë¡œ ì¶”ë¡ ì„ ëŒë¦¬ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì£¼ì˜! ëª¨ë¸ì„ í•™ìŠµí•œ ì´í›„ì— ëŒë¦¬ë©´ í•™ìŠµí•œ ëª¨ë¸ë¡œ ë™ì‘í•˜ë¯€ë¡œ ìœ ì˜í•˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     easy                 medium               hard                 extra                all                 \n",
      "count                12                   50                   21                   17                   100                 \n",
      "=====================   EXECUTION ACCURACY     =====================\n",
      "execution            0.417                0.000                0.000                0.000                0.050               \n"
     ]
    }
   ],
   "source": [
    "!cd test-suite-sql-eval-master && python evaluation.py --gold gold.txt --pred base_model_predict.txt --db database/ --etype exec --plug_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwrVPUnyMTpC"
   },
   "source": [
    "# 5. Text-to-SQL task ëª¨ë¸ LoRA fine-tuning\n",
    "\n",
    "LoRA ì„¤ì •ê³¼ Trainer ì„¤ì •ì„ í•˜ê³  ëª¨ë¸ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hL-teOqmMTpC"
   },
   "source": [
    "LoRA config ì„¤ì •ì„ í•©ë‹ˆë‹¤. ìì„¸í•œ ì„¤ì •ì€ [Huggingface LoRA Config](https://huggingface.co/docs/peft/package_reference/lora#peft.LoraConfig)ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_PLkHLNkMTpC"
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.0,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]  # safe default for many LLMs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1bLeGpuMTpD"
   },
   "source": [
    "### SFTConfig ì£¼ìš” ì„¤ì • ì„¤ëª…\n",
    "ê° ì„¤ì •ë“¤ì€ ê¸°ë³¸ì ì¸ AIì— ëŒ€í•œ ì§€ì‹ì´ í•„ìš”í•œ ë¶€ë¶„ë“¤ì´ ë§ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ê° ì„¤ì •ë“¤ì€ í•˜ë‚˜í•˜ë‚˜ ë¸”ë¡œê·¸ ê¸€ì„ ì°¸ê³ í•´ê°€ë©° ê¹Šì´ ì´í•´í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "1. output_dir\n",
    "- ì„¤ëª…: í•™ìŠµì´ ëë‚œ ëª¨ë¸ ê°€ì¤‘ì¹˜, ì²´í¬í¬ì¸íŠ¸, ë¡œê·¸ë¥¼ ì €ì¥í•  ë””ë ‰í„°ë¦¬ (ë˜ëŠ” Hugging Face Hub ì €ì¥ì†Œ ì´ë¦„)\n",
    "- ì¤‘ìš”ì„±: ì‹¤í—˜ ê²°ê³¼ë¥¼ ì¬í˜„í•˜ê±°ë‚˜ ì´ì–´ì„œ í•™ìŠµí•˜ë ¤ë©´ í•„ìˆ˜ë¡œ ì„¤ì •í•´ì•¼ í•¨\n",
    "\n",
    "2. max_seq_length\n",
    "- ì„¤ëª…: í•œ í•™ìŠµ ìƒ˜í”Œì˜ ìµœëŒ€ í† í° ê¸¸ì´\n",
    "- ì˜í–¥:\n",
    "\t1. ê¸¸ì´ë¥¼ í¬ê²Œ í•˜ë©´ ë” ê¸´ ë¬¸ì¥ì„ í•™ìŠµí•  ìˆ˜ ìˆìœ¼ë‚˜ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€\n",
    "\t2. ë„ˆë¬´ ì‘ìœ¼ë©´ ê¸´ ë¬¸ì¥ì´ ì˜ë ¤ì„œ í•™ìŠµ í’ˆì§ˆ ì €í•˜\n",
    "\n",
    "3. packing\n",
    "\t- ì„¤ëª…: ì—¬ëŸ¬ ì§§ì€ ìƒ˜í”Œì„ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ë¡œ ì´ì–´ ë¶™ì—¬(max_seq_lengthê¹Œì§€) í•™ìŠµ\n",
    "\t- ì¥ì : GPU ë©”ëª¨ë¦¬ íš¨ìœ¨ â†‘, í•™ìŠµ ì†ë„ â†‘ (íŒ¨ë”© ë‚­ë¹„ ê°ì†Œ)\n",
    "\t- ì£¼ì˜ì : ì‹œí€€ìŠ¤ ì‚¬ì´ë¥¼ êµ¬ë¶„í•˜ëŠ” special token(EOS ë“±)ì„ ë„£ì–´ì•¼ ë°ì´í„° ì„ì„ ë°©ì§€\n",
    "  - PACKING ì˜ˆì‹œ\n",
    "\n",
    "    ë°ì´í„°ì…‹ ìƒ˜í”Œì´ ê°ê° ë…ë¦½ëœ ì‹œí€€ìŠ¤ë¡œ í•™ìŠµë˜ê³  í•™ìŠµí•  í† í°ë“¤ì´ ì§§ìœ¼ë©´ íŒ¨ë”©ì´ ë§ì•„ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "    ```\n",
    "    ìƒ˜í”Œ 1: [USER] ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ? [EOS] [PAD] [PAD] [PAD] ...\n",
    "    ìƒ˜í”Œ 2: [USER] ë‚´ì¼ ë¹„ ì™€? [EOS] [PAD] [PAD] [PAD] ...\n",
    "    ìƒ˜í”Œ 3: [USER] ì£¼ë§ ì¼ì • ë³´ì—¬ì¤˜ [EOS] [PAD] [PAD] ...\n",
    "    ```\n",
    "    GPUëŠ” [PAD]ë„ ì—°ì‚°í•´ì•¼ í•˜ë¯€ë¡œ ë©”ëª¨ë¦¬ ë‚­ë¹„ & ì†ë„ ì €í•˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.\n",
    "\n",
    "    ì§§ì€ ìƒ˜í”Œë“¤ì„ ì´ì–´ë¶™ì´ê³ , ìƒ˜í”Œ ì‚¬ì´ì— EOS ê°™ì€ êµ¬ë¶„ í† í°ì„ ì¶”ê°€í•˜ì—¬ ìµœëŒ€ ê¸¸ì´(max_seq_length)ì— ë§ê²Œ í•˜ë‚˜ì˜ ê¸´ ì‹œí€€ìŠ¤ë¡œ ë¬¶ìŠµë‹ˆë‹¤.\n",
    "\n",
    "    Packed ì‹œí€€ìŠ¤:\n",
    "    ```\n",
    "    [USER] ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ? [EOS]\n",
    "    [USER] ë‚´ì¼ ë¹„ ì™€? [EOS]\n",
    "    [USER] ì£¼ë§ ì¼ì • ë³´ì—¬ì¤˜ [EOS]\n",
    "    ```\n",
    "    - íŒ¨ë”©ì´ ê±°ì˜ ì—†ê³  GPU ì—°ì‚° íš¨ìœ¨ â†‘\n",
    "    - í•œ ì‹œí€€ìŠ¤ ì•ˆì—ì„œ ì—¬ëŸ¬ ì˜ˆì‹œë¥¼ í•œ ë²ˆì— í•™ìŠµ â†’ í•™ìŠµ ì†ë„ â†‘\n",
    "    - `Packing=False` : `[ìƒ˜í”Œ1][PAD PAD PAD] [ìƒ˜í”Œ2][PAD PAD PAD]`\n",
    "    - `Packing=True` : `[ìƒ˜í”Œ1][EOS][ìƒ˜í”Œ2][EOS][ìƒ˜í”Œ3][EOS]\t`\n",
    "\n",
    "4. num_train_epochs\n",
    "- ì„¤ëª…: ì „ì²´ ë°ì´í„°ì…‹ì„ ëª‡ ë²ˆ ë°˜ë³µí•´ì„œ í•™ìŠµí• ì§€ ê²°ì •\n",
    "- íŒ: LoRA/QLoRAëŠ” ì ì€ Epoch(2~3)ìœ¼ë¡œë„ ì˜ ìˆ˜ë ´í•˜ëŠ” ê²½ìš°ê°€ ë§ìŒ\n",
    "\n",
    "5. per_device_train_batch_size\n",
    "- ì„¤ëª…: GPU í•œ ì¥(ë˜ëŠ” ì¥ì¹˜ í•˜ë‚˜)ì—ì„œ í•œ ë²ˆì— ì²˜ë¦¬í•  ìƒ˜í”Œ ê°œìˆ˜\n",
    "- ì¡°ì ˆ í¬ì¸íŠ¸: GPU ë©”ëª¨ë¦¬ì— ë§ì¶° ì¡°ì ˆ. ì‘ê²Œ í•˜ë©´ gradient_accumulation_stepsë¡œ ë³´ì™„ ê°€ëŠ¥\n",
    "\n",
    "6. gradient_accumulation_steps\n",
    "- ì„¤ëª…: ì—¬ëŸ¬ ìŠ¤í…ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ëˆ„ì í•´ í•œ ë²ˆë§Œ ì—­ì „íŒŒ/ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "- ì¥ì : ì‘ì€ ë°°ì¹˜ë¡œë„ í° effective batch size êµ¬í˜„ ê°€ëŠ¥\n",
    "- ì˜ˆì‹œ: batch_size=1, grad_accum=4 â†’ ì‹¤ì œ batch size = 4ì™€ ë¹„ìŠ·í•œ íš¨ê³¼\n",
    "- `gradient_accumulation_steps`ì€ [ë§í¬]()ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "7. gradient_checkpointing\n",
    "- ì„¤ëª…: ìˆœì „íŒŒ(forward) ì¤‘ ì¼ë¶€ ì¤‘ê°„ ê°’ì„ ì €ì¥í•˜ì§€ ì•Šê³  í•„ìš”í•  ë•Œ ë‹¤ì‹œ ê³„ì‚°\n",
    "- ì¥ì : GPU ë©”ëª¨ë¦¬ ì ˆì•½ (íŠ¹íˆ ëŒ€í˜• ëª¨ë¸ í•™ìŠµ ì‹œ í•„ìˆ˜)\n",
    "- ë‹¨ì : ì—°ì‚°ëŸ‰ ì¦ê°€ â†’ í•™ìŠµ ì†ë„ ì†Œí­ ëŠë ¤ì§\n",
    "\n",
    "8. optim\n",
    "- ì„¤ëª…: ì‚¬ìš©í•  ì˜µí‹°ë§ˆì´ì € ì„ íƒ (adamw_torch_fusedëŠ” PyTorchì˜ fused AdamW)\n",
    "- ì¥ì : ì¼ë°˜ AdamWë³´ë‹¤ ë¹ ë¥´ê³  ë©”ëª¨ë¦¬ íš¨ìœ¨ ì¢‹ìŒ (ì§€ì› GPU í•„ìš”)\n",
    "\n",
    "9. logging_steps\n",
    "- ì„¤ëª…: ëª‡ stepë§ˆë‹¤ í•™ìŠµ ë¡œê·¸ë¥¼ ê¸°ë¡í• ì§€\n",
    "- íŒ: ë„ˆë¬´ ì‘ìœ¼ë©´ ë¡œê·¸ ê³¼ë‹¤, ë„ˆë¬´ í¬ë©´ í•™ìŠµ ì¶”ì  í˜ë“¦ â†’ 10~50 step ì •ë„ ê¶Œì¥\n",
    "\n",
    "10. save_strategy\n",
    "- ì„¤ëª…: ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì‹œì  (epoch, steps, no)\n",
    "- ì˜ˆì‹œ: \"epoch\" â†’ ê° epochê°€ ëë‚  ë•Œë§ˆë‹¤ ì €ì¥\n",
    "\n",
    "11. learning_rate\n",
    "- ì„¤ëª…: ëª¨ë¸ í•™ìŠµë¥ \n",
    "- íŒ: QLoRA ë…¼ë¬¸ì—ì„œ 2e-4ê°€ ì•ˆì •ì ì´ë¼ê³  ê¶Œì¥\n",
    "- ì£¼ì˜: ì§€ë‚˜ì¹˜ê²Œ ë†’ìœ¼ë©´ loss í­ì£¼, ë‚®ìœ¼ë©´ í•™ìŠµ ëŠë¦¼\n",
    "\n",
    "12. fp16 / bf16\n",
    "- ì„¤ëª…: í•™ìŠµ ì‹œ ì—°ì‚° ì •ë°€ë„ ì„ íƒ\n",
    "- fp16: ëŒ€ë¶€ë¶„ GPU ì§€ì›, ë©”ëª¨ë¦¬ ì ˆì•½, ì†ë„ ë¹ ë¦„\n",
    "- bf16: ìµœì‹  GPU(Ampere ì´ìƒ)ì—ì„œ ê¶Œì¥, ì•ˆì •ì„± ë” ì¢‹ìŒ\n",
    "- íŒ: Colab A100/T4 â†’ fp16 / A100(Ampere) ì´ìƒ â†’ bf16 ì¶”ì²œ\n",
    "\n",
    "13. max_grad_norm\n",
    "- ì„¤ëª…: Gradient clipping ê°’ (ë„ˆë¬´ í° gradientë¥¼ ì˜ë¼ í•™ìŠµ ì•ˆì •í™”)\n",
    "- QLoRA ê¶Œì¥ê°’: 0.3\n",
    "\n",
    "14. warmup_ratio\n",
    "- ì„¤ëª…: í•™ìŠµ ì´ˆê¸°ì— learning rateë¥¼ ì²œì²œíˆ ì˜¬ë¦¬ëŠ” ë¹„ìœ¨\n",
    "- ì¥ì : í•™ìŠµ ì•ˆì •í™”, ì´ˆê¸° ì†ì‹¤ í­ì£¼ ë°©ì§€\n",
    "- QLoRA ë…¼ë¬¸ ê°’: 0.03 (~3% ë‹¨ê³„ëŠ” warmup)\n",
    "\n",
    "15. lr_scheduler_type\n",
    "- ì„¤ëª…: í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ ë°©ì‹\n",
    "- constant: í•™ìŠµ ë‚´ë‚´ ì¼ì •í•œ í•™ìŠµë¥ \n",
    "- (ë‹¤ë¥¸ ì˜µì…˜: linear, cosine ë“±)\n",
    "\n",
    "16. push_to_hub\n",
    "- ì„¤ëª…: í•™ìŠµì´ ëë‚œ ëª¨ë¸ì„ Hugging Face Hubì— ìë™ ì—…ë¡œë“œí• ì§€ ì—¬ë¶€\n",
    "- í˜‘ì—…/ê³µìœ : íŒ€ì›ì´ë‚˜ ê³µê°œ í”„ë¡œì íŠ¸ì— ìœ ìš©\n",
    "\n",
    "17. report_to\n",
    "- ì„¤ëª…: í•™ìŠµ ë©”íŠ¸ë¦­ì„ ì–´ë””ë¡œ ë³´ë‚¼ì§€ (ì˜ˆ: \"tensorboard\", \"wandb\")\n",
    "- ì¥ì : í•™ìŠµ ê³¼ì • ì‹œê°í™” ê°€ëŠ¥\n",
    "\n",
    "í•™ìŠµ ì„¤ì •ì„ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNU2cMBqMTpD"
   },
   "outputs": [],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "output_dir = \"outputs\"\n",
    "num_train_epochs=1\n",
    "per_device_train_batch_size = 1 # GPUê°€ ë¶€ì¡±í•˜ë‹¤ë©´ í•´ë‹¹ ê°’ì„ ì¤„ì—¬ì£¼ì„¸ìš”.\n",
    "gradient_accumulation_steps = 4\n",
    "warmup_ratio = 0.03\n",
    "max_steps = 1000 # í•™ìŠµ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦°ë‹¤ë©´ í•´ë‹¹ ê°’ì„ ì¤„ì—¬ì£¼ì„¸ìš”.\n",
    "learning_rate = 2e-5\n",
    "logging_steps = 1\n",
    "weight_decay = 0.01\n",
    "max_grad_norm=1.0\n",
    "lr_scheduler_type = \"linear\"\n",
    "report_to = \"none\" # Use this for WandB etc\n",
    "bf16=False\n",
    "gradient_checkpointing=False\n",
    "optim=\"adamw_torch\"\n",
    "\n",
    "train_cfg = SFTConfig(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    weight_decay=weight_decay,\n",
    "    logging_steps=logging_steps,\n",
    "    save_steps=max_steps,\n",
    "    max_steps=max_steps,\n",
    "    fp16=False if bf16 else True,\n",
    "    bf16=bf16,\n",
    "    report_to=report_to,\n",
    "    gradient_checkpointing=gradient_checkpointing,\n",
    "    optim=optim,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7wK6RFbMTpD"
   },
   "source": [
    "í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "hXlnFESxMTpD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SSAFY\\lucas\\skeleton-2\\.venv\\Lib\\site-packages\\peft\\mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SSAFY\\lucas\\skeleton-2\\.venv\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    train_dataset = train_dataset.select(range(max_steps * per_device_train_batch_size)), # max_steps * batch_size ë§Œí¼ë§Œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "    peft_config=peft_config,\n",
    "    args = train_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_k2339jORRjT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 01:32, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.540800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.745800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.759600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.015100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.349700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.219400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.117100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.479700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.619300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.745400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.638600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.319600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.629300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.178500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.093200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.527700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.158200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.663200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.378400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.397200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.801400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.062800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.136600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.982300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.211800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.937100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.703000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.139500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.561700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.608900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.937300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.822700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.569600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.667200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.873800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.493200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.610200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.510200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.777100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.537300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.669100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.531400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.666700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.356800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.444600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.493300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.393100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.469400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.577200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.402400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.257400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.359800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.156800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.327500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.349300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.200900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.315500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.474500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.210900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.744900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.305600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.319400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.191400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.447800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.285100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.413600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.224100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.150800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.190700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.180500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.173500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.187400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.448400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.199600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.245300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.418100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.367200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.579700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.134300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.080500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.195200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.239200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=100, training_loss=0.8179761552810669, metrics={'train_runtime': 93.8791, 'train_samples_per_second': 4.261, 'train_steps_per_second': 1.065, 'total_flos': 126295603765248.0, 'train_loss': 0.8179761552810669, 'epoch': 4.0})\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()\n",
    "print(trainer_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LoRAë¥¼ ì €ì¥í•˜ëŠ” ë°©ì‹ì€ ë‘ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "1. base modelì— LoRA weightë¥¼ mergeí•´ì„œ ì €ì¥í•˜ëŠ” ë°©ì‹\n",
    "2. LoRA weightë§Œ ë”°ë¡œ ì €ì¥í•˜ëŠ” ë°©ì‹\n",
    "\n",
    "ë‘ ë°©ì‹ ëª¨ë‘ ê°€ëŠ¥í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” 2ë²ˆ ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. ë§ì€ í•™ìŠµì„ ëŒë¦°ë‹¤ë©´ 1ë²ˆë³´ë‹¤ëŠ” 2ë²ˆì´ ë”ìš± ë¹„ìš© íš¨ìœ¨ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "8qORft1cMTpD"
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Save LoRA adapter (small)\n",
    "# ============================================\n",
    "merge_and_save = False\n",
    "if merge_and_save:\n",
    "    trainer.model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    print(f\"LoRA adapter saved to: {output_dir}\")\n",
    "\n",
    "# ============================================\n",
    "# (Optional) Merge LoRA into base weights and save a full model\n",
    "# WARNING: creates a large model; only do this if you need standalone weights\n",
    "# ============================================\n",
    "if merge_and_save:\n",
    "    from peft import AutoPeftModelForCausalLM\n",
    "    merged_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "        output_dir,\n",
    "        torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    merged_model = merged_model.merge_and_unload()\n",
    "    merged_dir = output_dir + \"-merged\"\n",
    "    merged_model.save_pretrained(merged_dir, safe_serialization=True)\n",
    "    tokenizer.save_pretrained(merged_dir)\n",
    "    print(f\"Merged full model saved to: {merged_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR6oXaK5MTpD"
   },
   "source": [
    "ëª¨ë¸ ê²°ê³¼ë¬¼ì´ ì˜ ë‚˜ì˜¤ëŠ”ì§€ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤. ìš°ì„  í•™ìŠµ ë°ì´í„°ë¡œ í•™ìŠµì´ ì˜ ë˜ì—ˆëŠ”ì§€ í™•ì¸ë§Œ í•´ë³´ê³  ì‹¤ì œ ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ëŠ” í‰ê°€ë¥¼ í†µí•´ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "4Ku5T0enMTpD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì •ë‹µ : SELECT T2.company_name FROM movie AS T1 JOIN culture_company AS T2 ON T1.movie_id  =  T2.movie_id WHERE T1.year  =  1999\n",
      "\n",
      "SELECT T1.company_name FROM company AS T1 JOIN movie_directors AS T2 ON T1.company_id = T2.company_id WHERE T2.movie_year = 1999<|endofturn|>\n"
     ]
    }
   ],
   "source": [
    "text_idx = len(train_df) - 1\n",
    "\n",
    "test_input = [\n",
    "    {'role': 'system', 'content': system_prompt},\n",
    "    {'role': 'user', 'content': user_prompt.format(question=train_df[\"question\"][text_idx])},\n",
    "]\n",
    "print(\"ì •ë‹µ :\", train_df[\"query\"][text_idx])\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(test_input, add_generation_prompt=True, return_dict=True, return_tensors=\"pt\")\n",
    "input_prompt = tokenizer.apply_chat_template(test_input, add_generation_prompt=True, tokenize=False)\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(\n",
    "        **inputs.to(\"cuda\"),\n",
    "        max_new_tokens=128,\n",
    "        stop_strings=[\"<|endofturn|>\", \"<|stop|>\"],\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "print(tokenizer.batch_decode(output_ids)[0][len(input_prompt) - 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•´ë´…ì‹œë‹¤.\n",
    "\n",
    "ëª¨ë¸ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ì´ì „ì— jupyter notebookì€ ì»¤ë„ì„ ê³„ì† ì‹¤í–‰í•˜ê³  ìˆê¸° ë•Œë¬¸ì— jupyter notebookì„ restartë¥¼ í•´ì•¼ë§Œ jupyter notebookì—ì„œ ì‚¬ìš©í•˜ëŠ” GPUê°€ ë¹„ì›Œì§‘ë‹ˆë‹¤. ê¼­ jupyter notebookì„ ë¹„ìš°ê³  `python inference.py` ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”. `outputs/` ë””ë ‰í† ë¦¬ê°€ ìˆë‹¤ë©´ LoRA ëª¨ë¸ì„ ë¨¼ì € ë¶ˆëŸ¬ì˜¤ê²Œë” ì„¤ì •ì´ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "inferenceë¥¼ ëŒë¦° ì´í›„ì—ëŠ” `cd test-suite-sql-eval-master && python evaluation.py --gold gold.txt --pred predict.txt --db database/ --etype exec --plug_value` ëª…ë ¹ì–´ë¡œ í‰ê°€ë¥¼ ì§ì ‘ ì§„í–‰í•´ë³´ì‹œê¸¸ ë°”ëë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lucas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
